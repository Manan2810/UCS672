{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Data cleaning is a time consuming and unenjoyable task, yet it's a very important one. Keep in mind, \"garbage in, garbage out\".`\n",
    "\n",
    "#### Feeding dirty data into a model will give us results that are meaningless.\n",
    "\n",
    "### Objective:\n",
    "\n",
    "1. Getting the data \n",
    "2. Cleaning the data \n",
    "3. Organizing the data - organize the cleaned data into a way that is easy to input into other algorithms\n",
    "\n",
    "### Output :\n",
    "#### cleaned and organized data in two standard text formats:\n",
    "\n",
    "1. Corpus - a collection of text\n",
    "2. Document-Term Matrix - word counts in matrix format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at transcripts of various comedians and note their similarities and differences and find if the stand up comedian of your choice has comedy style different than other comedian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the transcripts of some comedian from [Scraps From The Loft](http://scrapsfromtheloft.com). \n",
    "\n",
    "You can take help of IMDB and select only 10 or 20 comedian having highest rating.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping, pickle imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "\n",
    "# Scrapes transcript data from scrapsfromtheloft.com\n",
    "def url_to_transcript(url):\n",
    "    '''Returns transcript data specifically from scrapsfromtheloft.com.'''\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    text = [p.text for p in soup.find()]\n",
    "    print(url)\n",
    "    return text\n",
    "\n",
    "# URLs of transcripts in scope\n",
    "urls = ['https://www.scmp.com/tech/big-tech/article/3215579/chatgpt-sparks-investment-frenzy-and-soul-searching-chinas-artificial-intelligence-drive',\n",
    "        'https://www.scmp.com/tech/policy/article/3212245/chinas-ambitious-e-cny-plan-faces-one-giant-hurdle-winning-over-1-billion-consumers-home',\n",
    "        'https://www.scmp.com/tech/tech-war/article/3205099/tech-war-chinas-push-forge-chip-coalition-asia-falters-washington-expected-tighten-screws-2023',\n",
    "        'https://www.scmp.com/tech/tech-trends/article/3182445/will-nft-metaverse-developments-hong-kong-help-deliver-citys-next',\n",
    "        'https://www.scmp.com/tech/big-tech/article/3253034/openais-sora-pours-cold-water-chinas-ai-dreams-text-video-advancements-prompt-more-soul-searching?campaign=fcdfc3fc-d4d9-11ee-b412-424a7df79dac&module=AI_Recommended_for_you_In-house&pgtype=section_tech',\n",
    "        'https://www.scmp.com/tech/big-tech/article/3133466/china-antitrust-tencents-outsized-share-online-music-streaming-market',\n",
    "        'https://www.scmp.com/tech/big-tech/article/3253033/tech-war-nvidias-stellar-results-show-it-can-thrive-amid-china-decoupling-it-lists-huawei-potential',\n",
    "       ]\n",
    "\n",
    "# Comedian names\n",
    "comedians = ['chatgpt', 'ecnyplan','techwar','metaverse','openai-sora','tencent','nvidia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.scmp.com/tech/big-tech/article/3215579/chatgpt-sparks-investment-frenzy-and-soul-searching-chinas-artificial-intelligence-drive\n",
      "https://www.scmp.com/tech/policy/article/3212245/chinas-ambitious-e-cny-plan-faces-one-giant-hurdle-winning-over-1-billion-consumers-home\n",
      "https://www.scmp.com/tech/tech-war/article/3205099/tech-war-chinas-push-forge-chip-coalition-asia-falters-washington-expected-tighten-screws-2023\n",
      "https://www.scmp.com/tech/tech-trends/article/3182445/will-nft-metaverse-developments-hong-kong-help-deliver-citys-next\n",
      "https://www.scmp.com/tech/big-tech/article/3253034/openais-sora-pours-cold-water-chinas-ai-dreams-text-video-advancements-prompt-more-soul-searching?campaign=fcdfc3fc-d4d9-11ee-b412-424a7df79dac&module=AI_Recommended_for_you_In-house&pgtype=section_tech\n",
      "https://www.scmp.com/tech/big-tech/article/3133466/china-antitrust-tencents-outsized-share-online-music-streaming-market\n",
      "https://www.scmp.com/tech/big-tech/article/3253033/tech-war-nvidias-stellar-results-show-it-can-thrive-amid-china-decoupling-it-lists-huawei-potential\n"
     ]
    }
   ],
   "source": [
    "# # Actually request transcripts (takes a few minutes to run)\n",
    "transcripts = [url_to_transcript(u) for u in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: transcripts: File exists\n"
     ]
    }
   ],
   "source": [
    "# # Pickle files for later use\n",
    "\n",
    "# # Make a new directory to hold the text files\n",
    "!mkdir transcripts\n",
    "\n",
    "for i, c in enumerate(comedians):\n",
    "   with open(\"transcripts/\" + c + \".txt\", \"wb\") as file:\n",
    "     pickle.dump(transcripts[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled files\n",
    "data = {}\n",
    "for i, c in enumerate(comedians):\n",
    "    with open(\"transcripts/\" + c + \".txt\", \"rb\") as file:\n",
    "        data[c] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chatgpt', 'ecnyplan', 'techwar', 'metaverse', 'openai-sora', 'tencent', 'nvidia'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure data has been loaded properly\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT sparks investment frenzy and soul searching in China’s artificial intelligence drive | South China Morning Post ',\n",
       " 'South China Morning PostAdvertisementAdvertisementArtificial intelligence+ FOLLOWGet more with myNEWSA personalised news feed of stories that matter to youLearn more China has been pouring billions of dollars into artificial intelligence development, but censorship and technological limitations may hinder the country’s drive to build a a true competitor to ChatGPT. Illustration: Lau Ka-kuenTechBig TechChatGPT sparks investment frenzy and soul searching in China’s artificial intelligence driveWhile China had declared AI strategically important as early as 2018, ChatGPT has shattered illusions about the country’s technological prowess\\nA censored internet, compounded by the lack of access to advanced chips, could hinder China’s ambitions to create a true equivalent to ChatGPT\\nArtificial intelligence+ FOLLOWBen Jiangin BeijingandCoco Fengin BeijingPublished: 10:00am, 1 Apr, 2023Why you can trust SCMP When the world first witnessed the power of OpenAI’s conversational bot ChatGPT late last year, one social media post quickly went viral in China, attempting to explain why this artificial intelligence (AI) breakthrough did not happen in the country.The most widely-shared answer, provided by an anonymous author, was that Chinese technology firms were just too short-sighted to bear the cost of long-term investment, choosing instead to rush towards technologies that can be quickly commercialised.\\n“When the kid next door publishes a revolutionary doctorate paper, don’t ask why that kid is so smart,” it said. “You also have a smart kid in your house, but instead of supporting his study, you asked him to make quick money while he was still able to perform manual labour.”Many netizens find the metaphor apt in describing the root of China’s technological shortcomings. Despite strong policy and financial support by the state, as well as ample private investment, the country has been unable to beat the US to the punch in creating a cutting-edge AI chatbot like ChatGPT.In 2018, President Xi Jinping conducted a special study session with the Politburo. It concluded that AI was strategically important, and could lead to a technological revolution and industrial changes with “profound impact on economic development, social progress, and the pattern of the international political economy”.With the blessing of China’s top leadership, government and private funding poured into domestic AI start-ups.Chinese AI start-up launched a household robot in 2022, designed to play Chinese chess with humans. Photo: HandoutIn the ensuing years, the country saw the emergence of the “four little dragons” – Cloudwalk Technology, Megvii, SenseTime, and Yitu – all focused on the AI field of visual recognition.Meanwhile, commercial products bearing the AI label have flooded the Chinese market. SenseTime, for instance, launched a robot designed solely for teaching kids how to play chess.By 2021, Chinese firms claimed to have produced 21 large language models, up from just two in 2020, putting them on a par with the United States. A large language model, according to AI chip designer Nvidia, represents a deep-learning algorithm that can recognise, summarise, translate, predict and generate text and other content based on knowledge gained from massive data sets.But the arrival of ChatGPT shattered the illusion that China and the US were competing neck and neck in AI.Zhou Hongyi, founder of 360 Security Technology, says China’s AI development lags behind the level of OpenAI. Photo: ShutterstockChina’s knowledge level in AI is two to three years behind OpenAI, the San Francisco-based start-up that created ChatGPT, said Zhou Hongyi, founder of cybersecurity firm 360 Security Technology and an industry veteran with close ties to Chinese authorities, at the China Development Forum last weekend.That technological gap, however, has not deterred Chinese companies and entrepreneurs from touting their own plans to launch their own ChatGPT rivals in the country, where the chatbot is not officially available, because of the government’s attitude towards uncensored content.In March, internet search giant Baidu launched Ernie Bot, becoming the first major tech company in China to launch its own GPT-like service. Wang Huiwen, co-founder of on-demand services giant Meituan, and Lee Kai-fu, former China head of Google, have both started new ventures to explore the business potential of generative AI.But analysts caution that this gold rush could be short-lived owing to lack of technical expertise and experience, compounded by US export restrictions on AI chips, which would hinder the development of a true ChatGPT-equivalent in China.Lee Kai-fu, former head of Google China, has launched a new venture looking into the business potential of ChatGPT-like technologies. Photo: Edmond SoThe fanfare around ChatGPT only shows how much the market is craving for a new investment narrative, according to Bo Pei, an equity analyst at Tiger Securities. “After so many years of development, both the Western and Chinese internet industries are saturated and thirsting for a new direction.”“It is questionable how soon ChatGPT-like tools will actually make an impact or produce meaningful revenue,” Bo said.One big obstacle is China’s walled internet. With the Chinese government prohibiting the country’s more than 1 billion internet users from accessing uncensored content, the materials that researchers can use to train AI engines are more limited than in the West.A random test conducted by the Post last month, for example, found that Baidu’s Ernie Bot was unable to answer questions related to topics deemed politically sensitive by Beijing. When asked if China was a democratic nation, the chatbot ducked the question, simply replying that it “hasn’t learned how to answer this question yet”.Baidu CEO Robin Li Yanhong introduces the functions of Ernie Bot during a launch event in Beijing on March 16. Photo: AP Photo“Censorship could certainly hinder China’s ability to develop a local equivalent to ChatGPT,” Dahlia Peterson, a research analyst at Georgetown University’s Centre for Security and Emerging Technology, said in February.“Even if [Chinese] AI companies are able to access and utilise global data and research resources to train their AI models, it is unlikely Chinese authorities will allow them to use any material deemed as politically sensitive in their replies,” she added.While censorship will not stop China from coming up with its own answers to ChatGPT, much in the same way that the country developed its own search engines after Google pulled out of the market, it could take two to three years for Chinese industry players to develop models that are at least 80 per cent as powerful as ChatGPT, according to research company Third Bridge.And as China continues to fence off its internet, its gap with global AI leaders, such as the US, could widen. Within just four months after the public launch of ChatGPT in November, OpenAI released its next-generation language prediction model GPT-4, which has more sophisticated capabilities, including the ability to analyse images.A sign at the Nvidia headquarters in Santa Clara, California. Photo: Getty Images via AFPChina’s lack of access to the best chips for AI training could further delay its efforts to catch up with the US, according to Phelix Lee, an equity analyst at Morningstar Asia.American semiconductor giant Nvidia, which holds a virtual monopoly over high-end AI chips, is restricted by Washington from exporting its H100 and A100 chips to clients in China. The company now produces tailor-made chips, which are of lower performance, for the Chinese market.Chinese AI “development may be bottlenecked by US restrictions if China is unable to increase hardware sufficiency, and the severity of the bottleneck depends on how sophisticated AI systems become”, Lee said.The immensity of that challenge may well be illustrated by the reluctance of Chinese tech giants, save for Baidu, to show off any ChatGPT-like services to the public.Alibaba Group Holding, which has invested in large language models, has not said when it will roll out its own ChatGPT rival. Photo: BloombergAlibaba Group Holding, owner of the Post, has yet to provide a timetable for the launch of a commercial product based on its large language models, despite having invested in AI for years.Tencent Holdings has not provided any launch plans either, only saying it “will keep investing in cutting-edge technologies”, such as machine learning.Baidu, meanwhile, finds its Ernie Bot being constantly compared to ChatGPT. While the company’s shares gained 14 per cent on the February day that it announced plans to launch an intelligent chatbot, they lost 10 per cent on Ernie Bot’s launch day, when founder Robin Li Yanhong showed the technology with pre-recorded videos rather than a live demonstration.Last month, Li admitted that Ernie Bot lagged behind ChatGPT for about “one or two months”. But he also played down the geopolitical implications of Ernie Bot, saying that it “isn’t a tool for China to compete against the United States”.Sam Altman, CEO and co-founder of Open AI, speaks during an event at the Microsoft headquarters in Redmond, Washington in February. Photo: BloombergIt is too early to predict how much revenue or profit companies can generate from the likes of ChatGPT, as businesses are still exploring real-life applications of these chat bots, according to Wang Kai, a senior equity analyst at Morningstar Asia.“We are encouraged by the possibilities, but we still need to figure out how exactly [chatbots] will be monetised,” he said.Baidu has said it wants to integrate Ernie Bot across all its existing businesses, starting with its search engine, to “reshape the way information is generated and presented”. The technology will eventually be used to support Baidu’s smart speaker Xiaodu, self-driving unit Apollo, and video platform iQiyi, the company said.Over 650 Chinese organisations have announced partnerships with Ernie Bot, including smartphone brand Honor, travel-booking site Ctrip, carmaker Geely Auto, and electronics giants Lenovo Group and TCL, according to Baidu.\\n02:27Baidu unveils China’s answer to ChatGPT, sends stocks tumblingBaidu unveils China’s answer to ChatGPT, sends stocks tumblingStill, even as more Chinese tech firms jump on the chatbot bandwagon, many might see their costly bets failing to pan out, according to Lu Yanxia, research director at information technology consultancy IDC.Solely relying on large language models will not provide a sustained edge for any firm, Lu wrote in a research note in February. ChatGPT-like technologies will also have a limited impact on the market at the moment, while many related AI models might even become irrelevant in the long run, she said.“The true revelation [of ChatGPT] is that these language models will evolve and contribute to the advent of general AI, and that the application of these language models will push for a paradigm shift in AI development and narrow down the industry chain,” the research concluded.Some experts have gone as far as calling for tech companies and researchers around the world to pause the training of AI models more powerful than GPT-4.Tesla CEO Elon Musk is among dozens of tech industry veterans who have signed an open letter calling for a halt in the training of AI models more intelligent than GPT-4. Photo: Getty Images/TNS“AI systems with human-competitive intelligence can pose profound risks to society and humanity,” the Future of Life Institute wrote in an open letter this week, signed by Tesla founder Elon Musk, Apple co-founder Steve Wozniak and dozens of other tech veterans.“Should we automate away all the jobs, including the fulfilling ones? Should we develop non-human minds that might eventually outnumber, outsmart, make us obsolete and replace us?” it asked.“Such decisions must not be delegated to unelected tech leaders. Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable,” it said.20']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More checks\n",
    "data['chatgpt'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with numerical data, data cleaning often involves removing null values and duplicate data, dealing with outliers, etc. With text data, there are some common data cleaning techniques, which are also known as text pre-processing techniques.\n",
    "\n",
    "With text data, this cleaning process can go on forever. There's always an exception to every cleaning step. So, we're going to follow the MVP (minimum viable product) approach - start simple and iterate.\n",
    "### Assignment:\n",
    "1. Perform the following data cleaning on transcripts:\n",
    "i) Make text all lower case\n",
    "ii) Remove punctuation\n",
    "iii) Remove numerical values\n",
    "iv) Remove common non-sensical text (/n)\n",
    "v) Tokenize text\n",
    "vi) Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our data again\n",
    "next(iter(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that our dictionary is currently in key: comedian, value: list of text format\n",
    "next(iter(data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# We are going to change this to key: comedian, value: string format\n",
    "def combine_text(list_of_text):\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Combine it!\n",
    "data_combined = {key: [combine_text(value)] for (key, value) in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either keep it in dictionary format or put it into a pandas dataframe\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_combined).transpose()\n",
    "data_df.columns = ['transcript']\n",
    "data_df = data_df.sort_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the transcript for Ali Wong\n",
    "data_df.transcript.loc['ali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the updated text\n",
    "data_clean = pd.DataFrame(data_df.transcript.apply(round1))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the updated text\n",
    "data_clean = pd.DataFrame(data_clean.transcript.apply(round2))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment:\n",
    "1. Organized data in two standard text formats:\n",
    "   a) Corpus - corpus is a collection of texts, and they are all put together neatly in a pandas dataframe here.\n",
    "   b) Document-Term Matrix - word counts in matrix format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus: Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A corpus is a collection of texts, and they are all put together neatly in a pandas dataframe here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our dataframe\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's pickle it for later use\n",
    "data_df.to_pickle(\"corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Term Matrix: Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of the techniques we'll be using in future assignment, the text must be tokenized, meaning broken down into smaller pieces. The most common tokenization technique is to break down text into words. We can do this using scikit-learn's ` CountVectorizer `, where every row will represent a different document and every column will represent a different word.\n",
    "\n",
    "In addition, with ` CountVectorizer `, we can remove stop words. Stop words are common words that add no additional meaning to text such as 'a', 'the', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.transcript)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "data_dtm.index = data_clean.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's pickle it for later use\n",
    "data_dtm.to_pickle(\"dtm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Let's also pickle the cleaned data (before we put it in document-term matrix format) and the CountVectorizer object\n",
    "data_clean.to_pickle('data_clean.pkl')\n",
    "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Additional Assignments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you add an additional regular expression to the clean_text_round2 function to further clean the text?\n",
    "2. Play around with CountVectorizer's parameters. What is ngram_range? What is min_df and max_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
